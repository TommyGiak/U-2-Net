{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb98c18c",
   "metadata": {},
   "source": [
    "# 0. Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88887971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as standard_transforms\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from data_loader import Rescale\n",
    "from data_loader import RescaleT\n",
    "from data_loader import RandomCrop\n",
    "from data_loader import ToTensor\n",
    "from data_loader import ToTensorLab\n",
    "from data_loader import SemanticSalObjDataset\n",
    "\n",
    "from model import SU2NET\n",
    "from model import SU2NETP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af282e9",
   "metadata": {},
   "source": [
    "# 1. Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss(size_average=True)\n",
    "\n",
    "def muti_ce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v):\n",
    "\n",
    "\tloss0 = ce_loss(d0,labels_v)\n",
    "\tloss1 = ce_loss(d1,labels_v)\n",
    "\tloss2 = ce_loss(d2,labels_v)\n",
    "\tloss3 = ce_loss(d3,labels_v)\n",
    "\tloss4 = ce_loss(d4,labels_v)\n",
    "\tloss5 = ce_loss(d5,labels_v)\n",
    "\tloss6 = ce_loss(d6,labels_v)\n",
    "\n",
    "\tloss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
    "\tprint(\"l0: %3f, l1: %3f, l2: %3f, l3: %3f, l4: %3f, l5: %3f, l6: %3f\\n\"%(loss0.data.item(),loss1.data.item(),loss2.data.item(),loss3.data.item(),loss4.data.item(),loss5.data.item(),loss6.data.item()))\n",
    "\n",
    "\treturn loss0, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d4389",
   "metadata": {},
   "source": [
    "# 2. Set the directory of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'u2net' #'u2netp'\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'train_data' + os.sep)\n",
    "tra_image_dir = os.path.join('wounds' + os.sep)\n",
    "tra_label_dir = os.path.join('semantic_masks' + os.sep)\n",
    "\n",
    "image_ext = '.png'\n",
    "label_ext = '.png'\n",
    "\n",
    "model_dir = os.path.join(os.getcwd(), 'saved_models', model_name + os.sep)\n",
    "\n",
    "epoch_num = 5000\n",
    "batch_size_train = 4\n",
    "batch_size_val = 1\n",
    "train_num = 0\n",
    "val_num = 0\n",
    "\n",
    "tra_img_name_list = glob.glob(data_dir + tra_image_dir + '*' + image_ext)\n",
    "\n",
    "tra_lbl_name_list = []\n",
    "for img_path in tra_img_name_list:\n",
    "\timg_name = img_path.split(os.sep)[-1]\n",
    "\n",
    "\taaa = img_name.split(\".\")\n",
    "\tbbb = aaa[0:-1]\n",
    "\timidx = bbb[0]\n",
    "\tfor i in range(1,len(bbb)):\n",
    "\t\timidx = imidx + \".\" + bbb[i]\n",
    "\n",
    "\ttra_lbl_name_list.append(data_dir + tra_label_dir + imidx + label_ext)\n",
    "\n",
    "print(\"---\")\n",
    "print(\"train images: \", len(tra_img_name_list))\n",
    "print(\"train labels: \", len(tra_lbl_name_list))\n",
    "print(\"---\")\n",
    "\n",
    "train_num = len(tra_img_name_list)\n",
    "\n",
    "salobj_dataset = SemanticSalObjDataset(\n",
    "    img_name_list=tra_img_name_list,\n",
    "    lbl_name_list=tra_lbl_name_list,\n",
    "    transform=transforms.Compose([\n",
    "        RescaleT(320),\n",
    "        RandomCrop(288),\n",
    "        ToTensorLab(flag=0)]))\n",
    "\n",
    "salobj_dataloader = DataLoader(salobj_dataset, batch_size=batch_size_train, shuffle=True)#, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44afae0",
   "metadata": {},
   "source": [
    "# 3. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the net\n",
    "if(model_name=='u2net'):\n",
    "    net = SU2NET(in_ch=3, out_ch=4)\n",
    "elif(model_name=='u2netp'):\n",
    "    net = SU2NETP(in_ch=3, out_ch=4)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e24a9",
   "metadata": {},
   "source": [
    "# 4. Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb725051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"---define optimizer...\")\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0004, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer=optimizer, start_factor=1, end_factor=1/10, total_iters=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98606c1",
   "metadata": {},
   "source": [
    "# 5. Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95369d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"---start training...\")\n",
    "ite_num = 0\n",
    "running_loss = 0.0\n",
    "running_tar_loss = 0.0\n",
    "ite_num4val = 0\n",
    "save_frq = 5000 # save the model every 2000 iterations\n",
    "\n",
    "for epoch in range(0, epoch_num):\n",
    "    net.train()\n",
    "\n",
    "    for i, data in enumerate(salobj_dataloader):\n",
    "        ite_num = ite_num + 1\n",
    "        ite_num4val = ite_num4val + 1\n",
    "\n",
    "        inputs, labels = data['image'], data['label']\n",
    "\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs_v, labels_v = Variable(inputs.cuda(), requires_grad=False), Variable(labels.cuda(),\n",
    "                                                                                        requires_grad=False)\n",
    "        else:\n",
    "            inputs_v, labels_v = Variable(inputs, requires_grad=False), Variable(labels, requires_grad=False)\n",
    "\n",
    "        # y zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        d0, d1, d2, d3, d4, d5, d6 = net(inputs_v)\n",
    "        loss2, loss = muti_ce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # # print statistics\n",
    "        running_loss += loss.data.item()\n",
    "        running_tar_loss += loss2.data.item()\n",
    "\n",
    "        # del temporary outputs and loss\n",
    "        del d0, d1, d2, d3, d4, d5, d6, loss2, loss\n",
    "\n",
    "        print(\"[epoch: %3d/%3d, batch: %5d/%5d, ite: %d] train loss: %3f, tar: %3f \" % (\n",
    "        epoch + 1, epoch_num, (i + 1) * batch_size_train, train_num, ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
    "\n",
    "        if ite_num % save_frq == 0:\n",
    "\n",
    "            torch.save(net.state_dict(), model_dir + model_name+\"_bce_itr_%d_train_%3f_tar_%3f.pth\" % (ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
    "            running_loss = 0.0\n",
    "            running_tar_loss = 0.0\n",
    "            net.train()  # resume train\n",
    "            ite_num4val = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ff5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666e97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565deecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
